Schema Data Extraction Task ‚Äî Simple Guide

üéØ Goal

Collect all structured data schemas (JSON-LD) from pages of Bimeh.com and export them into an Excel file.

üìå What Needs to Be Done
1Ô∏è‚É£ Find All Website URLs

Get the full list of site pages (usually from the sitemap).

Example source:

https://bimeh.com/sitemap.xml

2Ô∏è‚É£ Extract Schema Data From Each Page

On every page, look for this tag:

<script type="application/ld+json">


This contains structured data like:

FAQPage

Product

Breadcrumb

Organization

Article

3Ô∏è‚É£ Parse the JSON-LD Content

For each schema found, collect:

Page URL

Schema type (@type)

Full JSON content

4Ô∏è‚É£ Save Results Into Excel

The final Excel file should include columns like:

URL	Schema Type	Raw JSON
page link	FAQPage	full schema data
üõ† Suggested Implementation Approach

Use a simple crawler script that:

Reads URLs from the sitemap

Visits each page

Extracts JSON-LD scripts

Saves everything into an .xlsx file

‚úÖ Expected Output

A single Excel file containing:

All site URLs with schema data

Each schema listed separately

Ready for SEO audit or documentation
